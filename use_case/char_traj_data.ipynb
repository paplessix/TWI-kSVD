{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Trajectories dataset\n",
    "\n",
    "Link to [Official repository](https://archive-beta.ics.uci.edu/dataset/175/character+trajectories) on UC Irvine\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description:\n",
    "\n",
    "Multiple, labelled samples of pen tip trajectories recorded whilst writing individual characters. All samples are from the same writer, for the purposes of primitive extraction. Only characters with a single pen-down segment were considered.\n",
    "\n",
    "Each character sample is a 3-dimensional pen tip velocity trajectory. This is contained in matrix format, with 3 rows and T columns where T is the length of the character sample.\n",
    "\n",
    "The characters here were used for a PhD study on primitive extraction using HMM based models. The data consists of 2858 character samples, contained in the cell array 'mixout'. The struct variable 'consts' contains a field consts.charlabels which provides ennummerated labels for the characters. consts.key provides the key for each label. The data was captured using a WACOM tablet. 3 Dimensions were kept - x, y, and pen tip force. The data has been numerically differentiated and Gaussian smoothed, with a sigma value of 2. Data was captured at 200Hz. The data was normalised with consts.datanorm. Only characters with a single 'PEN-DOWN' segment were considered. Character segmentation was performed using a pen tip force cut-off point. The characters have also been shifted so that their velocity profiles best match the mean of the set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download database\n",
    "\n",
    "Run the cell below to collect the archives in your folder.\n",
    "\n",
    "Safe cell that will create a folder `../trajectory_dataset` (), download and overwrite the files in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import requests\n",
    "\n",
    "if not os.path.exists(\"../trajectory_dataset\"):\n",
    "    os.mkdir(\"../trajectory_dataset\")\n",
    "    r = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/character-trajectories/mixoutALL_shifted.mat\")\n",
    "    open('../trajectory_dataset/mixoutALL_shifted.mat', 'wb').write(r.content)\n",
    "    r = requests.get(\" https://archive.ics.uci.edu/ml/machine-learning-databases/character-trajectories/trajectories.names\")\n",
    "\n",
    "    open('../trajectory_dataset/trajectories.names', 'wb').write(r.content)\n",
    "# ! wget -O ../trajectory_dataset/mixoutALL_shifted.mat https://archive.ics.uci.edu/ml/machine-learning-databases/character-trajectories/mixoutALL_shifted.mat\n",
    "# ! wget -O ../trajectory_dataset/trajectories.names https://archive.ics.uci.edu/ml/machine-learning-databases/character-trajectories/trajectories.names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "# load data in a python dictionnary\n",
    "mat = loadmat('../trajectory_dataset/mixoutALL_shifted.mat')\n",
    "\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the dataset\n",
    "\n",
    "n_samples = mat[\"mixout\"][0].__len__()\n",
    "\n",
    "print(f\"Number of samples:\\t {n_samples}\")\n",
    "\n",
    "\n",
    "# Loading samples labels\n",
    "keys = mat[\"consts\"][0,0][4]\n",
    "keys = [key - 1 for key in keys[0]]\n",
    "\n",
    "labels = mat[\"consts\"][0,0][3]\n",
    "labels = np.array([label[0] for label in labels[0]])\n",
    "\n",
    "samples_label = labels[[keys]][0]\n",
    "\n",
    "label_unique, label_count = np.unique(samples_label, return_counts=True)\n",
    "\n",
    "print()\n",
    "print(\"Data distribution:\")\n",
    "print(f\"{len(label_unique)} different class\")\n",
    "line_u = \"_______\" + str.join(\"_\", [\"___\" for _ in label_count]) + \"_\"\n",
    "print(line_u)\n",
    "char = \"|CHAR  | \" + str.join(\" | \", label_unique) + \" |\"\n",
    "print(char)\n",
    "line_d = \"|______|\" + str.join(\"|\", [\"___\" for _ in label_count]) + \"|\"\n",
    "print(line_d)\n",
    "count = \"|COUNT |\" + str.join(\"|\", [str(c) for c in label_count]) + \"|\"\n",
    "print(count)\n",
    "print(line_d)\n",
    "\n",
    "\n",
    "samples = mat[\"mixout\"][0]\n",
    "\n",
    "f_s = 200 #Hz sampling at 200Hz\n",
    "\n",
    "print(f\"\\n\\nN_features: \\t\\t{samples[0].shape[0]} ---> \\t(v_x, v_y, pen_tip_force)\")\n",
    "print(f\"Sampling frequency: \\t{f_s} Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rdm_sample_idx = np.random.randint(0, len(samples), 10)\n",
    "\n",
    "for i, i_sample in enumerate(rdm_sample_idx):\n",
    "\n",
    "    exsample = samples[i_sample]\n",
    "\n",
    "    x_speed = exsample[0]\n",
    "    y_speed = exsample[1]\n",
    "    pen_tip_f = exsample[2]\n",
    "    \n",
    "\n",
    "    # Conversion to trajectory beggining at point (0,0)\n",
    "    x = [0]\n",
    "    y = [0]\n",
    "\n",
    "    for x_v, y_v in zip(x_speed, y_speed):\n",
    "        x.append(x[-1] + x_v/f_s)\n",
    "        y.append(y[-1] + y_v/f_s)\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.scatter(x[:], y[:], c=np.arange(len(x)), s=5)\n",
    "\n",
    "    # To modulate the linewidth depending on the pen tip force \n",
    "    # plt.scatter(x[1:], y[1:], c=np.arange(len(x[1:])), s=2*np.abs(pen_tip_f))\n",
    "    \n",
    "    plt.plot(x, y, alpha=0.5)\n",
    "    \n",
    "    plt.title(samples_label[i_sample])\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    #plt.colorbar()\n",
    "\n",
    "plt.suptitle(\"Characters samples (start in indigo, end in yellow)\")\n",
    "plt.show()\n",
    "\n",
    "for i, i_sample in enumerate(rdm_sample_idx):\n",
    "\n",
    "    exsample = samples[i_sample]\n",
    "\n",
    "    pen_tip_f = exsample[2]\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(np.arange(len(pen_tip_f)), pen_tip_f)\n",
    "    plt.title(samples_label[i_sample])\n",
    "\n",
    "plt.suptitle(\"Pen tip force curves\")\n",
    "plt.show()\n",
    "\n",
    "for i, i_sample in enumerate(rdm_sample_idx):\n",
    "\n",
    "    exsample = samples[i_sample]\n",
    "\n",
    "    x_speed = exsample[0]\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(np.arange(len(x_speed)), x_speed)\n",
    "    plt.title(samples_label[i_sample])\n",
    "\n",
    "plt.suptitle(\"X speed (+ = right, - = down)\")\n",
    "plt.show()\n",
    "\n",
    "for i, i_sample in enumerate(rdm_sample_idx):\n",
    "\n",
    "    exsample = samples[i_sample]\n",
    "\n",
    "    y_speed = exsample[1]\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(np.arange(len(y_speed)), y_speed)\n",
    "    plt.title(samples_label[i_sample])\n",
    "\n",
    "plt.suptitle(\"Y speed (+ = up, - = left)\")\n",
    "plt.show()\n",
    "\n",
    "for i, i_sample in enumerate(rdm_sample_idx):\n",
    "\n",
    "    exsample = samples[i_sample]\n",
    "\n",
    "    x_speed = exsample[0]\n",
    "    y_speed = exsample[1]\n",
    "    pen_tip_f = exsample[2]\n",
    "    \n",
    "\n",
    "    # Conversion to trajectory beggining at point (0,0)\n",
    "    x = [0]\n",
    "    y = [0]\n",
    "\n",
    "    for x_v, y_v in zip(x_speed, y_speed):\n",
    "        x.append(x[-1] + x_v/f_s)\n",
    "        y.append(y[-1] + y_v/f_s)\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(np.arange(len(x)), x)\n",
    "    plt.title(samples_label[i_sample])\n",
    "\n",
    "plt.suptitle(\"X position\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i, i_sample in enumerate(rdm_sample_idx):\n",
    "\n",
    "    exsample = samples[i_sample]\n",
    "\n",
    "    x_speed = exsample[0]\n",
    "    y_speed = exsample[1]\n",
    "    pen_tip_f = exsample[2]\n",
    "    \n",
    "\n",
    "    # Conversion to trajectory beggining at point (0,0)\n",
    "    x = [0]\n",
    "    y = [0]\n",
    "\n",
    "    for x_v, y_v in zip(x_speed, y_speed):\n",
    "        x.append(x[-1] + x_v/f_s)\n",
    "        y.append(y[-1] + y_v/f_s)\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(np.arange(len(y)), y)\n",
    "    plt.title(samples_label[i_sample])\n",
    "\n",
    "plt.suptitle(\"Y position\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWI-kSVD on char-traj data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_speeds = []\n",
    "y_speeds = []\n",
    "pen_tip_forces = []\n",
    "max_len = 0\n",
    "min_len = 1000\n",
    "\n",
    "for sample in samples:\n",
    "    x_speeds.append(sample[0])\n",
    "    y_speeds.append(sample[1])\n",
    "    pen_tip_forces.append(sample[2])\n",
    "    \n",
    "    if len(sample[0]) > max_len:\n",
    "        max_len = len(sample[0])\n",
    "    \n",
    "    if len(sample[0]) < min_len:\n",
    "        min_len = len(sample[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Longueur minimale : {min_len}\")\n",
    "print(f\"Longueur maximale : {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x_speed in enumerate(x_speeds[:2]):\n",
    "\n",
    "    plt.subplot(2, 1, i+1)\n",
    "    plt.plot(np.arange(len(x_speed)), x_speed)\n",
    "    plt.title(samples_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from twi_ksvd.ksvd import TWI_kSVD\n",
    "from twi_ksvd.omp import TWI_OMP\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def eval_count(x, D_list, tau, r_window):\n",
    "    alphas, _ = TWI_OMP(x, D_list, tau=tau, r_window=r_window)\n",
    "\n",
    "    return alphas != 0\n",
    "\n",
    "\n",
    "def train_label(K, tau, max_iter, label, train_idx, test_idx, r_window):\n",
    "    \"\"\"\n",
    "    Train a dictionnary for the given label\n",
    "    \"\"\"\n",
    "\n",
    "    # x training\n",
    "    x_train = [x_speeds[i] for i in train_idx if samples_label[i] == label]\n",
    "    x_test = [x_speeds[i] for i in test_idx if samples_label[i] == label]\n",
    "\n",
    "    model_x = TWI_kSVD( K, max_iter=max_iter)\n",
    "    D_list = []\n",
    "\n",
    "    dico_idx = np.random.choice(np.arange(len(x_train)), K)\n",
    "    for i in range(K):\n",
    "        D_list.append(x_train[dico_idx[i]])\n",
    "\n",
    "    _, Dx = model_x.fit(x_train, D_list, tau, r_window=r_window)\n",
    "\n",
    "    counts_test = np.zeros(len(Dx), dtype=int)\n",
    "\n",
    "    with Pool(processes=None) as pool:\n",
    "        multiple_results = [pool.apply_async(eval_count, (x,Dx,tau, r_window)) for x in x_test]\n",
    "\n",
    "        for i in tqdm(range(len(x_test))):\n",
    "            c = multiple_results[i].get()\n",
    "            counts_test += c\n",
    "\n",
    "    final_x_dico = [atom for i, atom in enumerate(Dx) if counts_test[i] > 0]\n",
    "\n",
    "\n",
    "    # y training\n",
    "    y_train = [y_speeds[i] for i in train_idx if samples_label[i] == label]\n",
    "    y_test = [y_speeds[i] for i in test_idx if samples_label[i] == label]\n",
    "\n",
    "    model_y = TWI_kSVD( K, max_iter=max_iter)\n",
    "    D_list = []\n",
    "\n",
    "    dico_idx = np.random.choice(np.arange(len(y_train)), K)\n",
    "    for i in range(K):\n",
    "        D_list.append(y_train[dico_idx[i]])\n",
    "\n",
    "    _, Dy = model_x.fit(y_train, D_list, tau, r_window=r_window)\n",
    "\n",
    "    counts_test = np.zeros(len(Dy), dtype=int)\n",
    "\n",
    "    with Pool(processes=None) as pool:\n",
    "        multiple_results = [pool.apply_async(eval_count, (y,Dy,tau, r_window)) for y in y_test]\n",
    "\n",
    "        for i in tqdm(range(len(y_test))):\n",
    "            c = multiple_results[i].get()\n",
    "            counts_test += c\n",
    "\n",
    "    final_y_dico = [atom for i, atom in enumerate(Dy) if counts_test[i] > 0]\n",
    "\n",
    "    return final_x_dico, final_y_dico\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_dicos(K=8, tau=2, max_iter=30, labels=np.unique(samples_label), save_path = \"../trajectory_dataset/dictionnary/\", r_window=20):\n",
    "    \"\"\"\n",
    "    Train a dictionnary on training set for every letter\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Labels : \", labels)\n",
    "    train_idx, test_idx = train_test_split(np.arange(len(x_speeds)), test_size=0.3, stratify=samples_label)\n",
    "\n",
    "    for label in labels:\n",
    "\n",
    "        print(\"Training for label \" + label)\n",
    "\n",
    "        final_x_dico, final_y_dico = train_label(K, tau, max_iter, label, train_idx, test_idx, r_window)\n",
    "\n",
    "        print(f\"For label {label}, {len(final_x_dico)} x atoms and {len(final_y_dico)} y atoms\")\n",
    "        \n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        for atom in final_x_dico:\n",
    "            plt.plot(np.arange(len(atom)), atom)\n",
    "\n",
    "        plt.title(\"X_speeds / label \" + label)\n",
    "\n",
    "        plt.subplot(1, 2, 2)    \n",
    "        for atom in final_y_dico:\n",
    "            plt.plot(np.arange(len(atom)), atom)\n",
    "\n",
    "        plt.title(\"Y_speeds / label \" + label)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        for i, atom in enumerate(final_x_dico):\n",
    "            os.makedirs(save_path + \"/\" + label + \"/x_dico\", exist_ok=True)\n",
    "            np.save(save_path + \"/\" + label + \"/x_dico/atom_\" + str(i) + \".npy\", atom)\n",
    "\n",
    "        for i, atom in enumerate(final_y_dico):\n",
    "            os.makedirs(save_path + \"/\" + label + \"/y_dico\", exist_ok=True)\n",
    "            np.save(save_path + \"/\" + label + \"/y_dico/atom_\" + str(i) + \".npy\", atom)\n",
    "\n",
    "        print(\"Atoms saved in \" + save_path + \"/\" + label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dicos(K=8, tau=2, max_iter=30, labels=np.unique(samples_label)[-1:], save_path=\"../trajectory_dataset/23_03_2023/\", r_window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(len(x_speeds)), test_size=0.3, stratify=samples_label)\n",
    "\n",
    "x_train = [x_speeds[i][::2] for i in train_idx if samples_label[i] == 'a']\n",
    "x_test = [x_speeds[i][::2] for i in test_idx if samples_label[i] == 'a']\n",
    "\n",
    "y_train = [y_speeds[i][::2] for i in train_idx if samples_label[i] == 'a']\n",
    "y_test = [y_speeds[i][::2] for i in test_idx if samples_label[i] == 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twi_ksvd.ksvd import TWI_kSVD\n",
    "from scipy import signal\n",
    "\n",
    "# Au maximum 20 atomes pour décrire tous les signaux\n",
    "K = 5\n",
    "model_x = TWI_kSVD( K, max_iter=30)\n",
    "# En décrivant chaque signal par au plus 5 atomes\n",
    "tau = 2\n",
    "\n",
    "D_list = []\n",
    "\n",
    "dico_idx = np.random.choice(np.arange(len(x_train)), K)\n",
    "for i in range(K):\n",
    "    D_list.append(x_train[dico_idx[i]])\n",
    "\n",
    "    # atom_length = 50  #(min_len + (i  * (max_len - min_len)) // (K-1)) // 4\n",
    "\n",
    "    # phase = 2* np.pi * np.random.random(1)\n",
    "\n",
    "    # window = signal.windows.hamming(atom_length)\n",
    "\n",
    "    # window = window - np.min(window)\n",
    "    \n",
    "    # t = np.arange(atom_length) * np.random.random(1) / 5\n",
    "\n",
    "    # D_list.append(np.cos(t+phase)*window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, atom in enumerate(D_list):\n",
    "\n",
    "    plt.plot(np.arange(len(atom)), atom, label=f\"{i}\")\n",
    "\n",
    "plt.title(\"Initial random cosine atoms\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ax,Dx = model_x.fit(x_train, D_list, tau, r_window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ax, Dx = model_x.alphas, model_x.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Au maximum 20 atomes pour décrire tous les signaux\n",
    "K = 10\n",
    "model_y = TWI_kSVD( K, max_iter=30)\n",
    "# En décrivant chaque signal par au plus 5 atomes\n",
    "tau = 2\n",
    "\n",
    "D_list = []\n",
    "\n",
    "dico_idx = np.random.choice(np.arange(len(y_train)), K)\n",
    "for i in range(K):\n",
    "    D_list.append(y_train[dico_idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Ay,Dy = model_y.fit(y_train, D_list, tau, r_window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ay, Dy = model_y.alphas, model_y.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_count(x, D_list, tau, r_window):\n",
    "    alphas, _ = TWI_OMP(x, D_list, tau=tau, r_window=20)\n",
    "\n",
    "    return alphas != 0\n",
    "\n",
    "counts_train = np.zeros(len(Dx), dtype=int)\n",
    "\n",
    "with Pool(processes=None) as pool:\n",
    "    multiple_results = [pool.apply_async(eval_count, (x,Dx,tau, 20)) for x in x_train]\n",
    "\n",
    "    for i in tqdm(range(len(x_train))):\n",
    "        c = multiple_results[i].get()\n",
    "        counts_train += c\n",
    "\n",
    "\n",
    "counts_test = np.zeros(len(Dx), dtype=int)\n",
    "\n",
    "with Pool(processes=None) as pool:\n",
    "    multiple_results = [pool.apply_async(eval_count, (x,Dx,tau, 20)) for x in x_test]\n",
    "\n",
    "    for i in tqdm(range(len(x_test))):\n",
    "        c = multiple_results[i].get()\n",
    "        counts_test += c\n",
    "\n",
    "print(counts_test + counts_train)\n",
    "np.sum(counts_test + counts_train) == tau * (len(x_train) + len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts_test)\n",
    "print(counts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, atom in enumerate(Dx):\n",
    "    if counts_test[i] > 0:\n",
    "        plt.plot(np.arange(len(atom)), atom, label=f\"Atom {i} (counts = {counts_test[i]})\")\n",
    "\n",
    "plt.title(\"Final random cosine atoms (x_speeds)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_count(x, D_list, tau, r_window):\n",
    "    alphas, _ = TWI_OMP(x, D_list, tau=tau, r_window=20)\n",
    "\n",
    "    return alphas != 0\n",
    "\n",
    "counts_train = np.zeros(len(Dy), dtype=int)\n",
    "\n",
    "with Pool(processes=None) as pool:\n",
    "    multiple_results = [pool.apply_async(eval_count, (y,Dy,tau, 20)) for y in y_train]\n",
    "\n",
    "    for i in tqdm(range(len(y_train))):\n",
    "        c = multiple_results[i].get()\n",
    "        counts_train += c\n",
    "\n",
    "\n",
    "counts_test = np.zeros(len(Dy), dtype=int)\n",
    "\n",
    "with Pool(processes=None) as pool:\n",
    "    multiple_results = [pool.apply_async(eval_count, (y,Dy,tau, 20)) for y in y_test]\n",
    "\n",
    "    for i in tqdm(range(len(y_test))):\n",
    "        c = multiple_results[i].get()\n",
    "        counts_test += c\n",
    "\n",
    "print(counts_test + counts_train)\n",
    "np.sum(counts_test + counts_train) == tau * (len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, atom in enumerate(model_y.D):\n",
    "    if counts_test[i] > 0:\n",
    "        plt.plot(np.arange(len(atom)), atom, label=f\"Atom {i} (counts = {counts_test[i]})\")\n",
    "\n",
    "plt.title(\"Final random cosine atoms (y_speeds)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twi_ksvd.omp import TWI_OMP\n",
    "\n",
    "\n",
    "x_test\n",
    "for p, x in enumerate([x_train[i] for i in np.random.randint(0, len(x_train), 2)] + [x_test[i] for i in np.random.randint(0, len(x_test), 2)]):\n",
    "    alphas, deltas = TWI_OMP(x, Dx, tau=tau, r_window=20)\n",
    "\n",
    "    reconstructed_x_signal = np.zeros_like(x)\n",
    "\n",
    "    plt.subplot(4, 2, 2*p + 1)\n",
    "    for alpha, delta, atom in zip(alphas, deltas, Dx):\n",
    "        if alpha != 0:\n",
    "            reconstructed_x_signal += alpha * delta @ atom\n",
    "            plt.plot(atom)\n",
    "    \n",
    "    #plt.plot(reconstructed_x_signal)\n",
    "    plt.subplot(4, 2, 2*p + 2)\n",
    "    plt.plot(x)\n",
    "    plt.plot(reconstructed_x_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, y in enumerate([y_train[i] for i in np.random.randint(0, len(y_train), 2)] + [y_test[i] for i in np.random.randint(0, len(y_test), 2)]):\n",
    "    alphas, deltas = TWI_OMP(y, Dy, tau=tau, r_window=20)\n",
    "\n",
    "    reconstructed_y_signal = np.zeros_like(y)\n",
    "\n",
    "    plt.subplot(4, 2, 2*p + 1)\n",
    "    for alpha, delta, atom in zip(alphas, deltas, Dy):\n",
    "        if alpha != 0:\n",
    "            reconstructed_y_signal += alpha * delta @ atom\n",
    "            plt.plot(atom)\n",
    "    \n",
    "    plt.subplot(4, 2, 2*p + 2)\n",
    "    plt.plot(y)\n",
    "    plt.plot(reconstructed_y_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, (xs,ys) in enumerate([(x_train[i], y_train[i]) for i in np.random.randint(0, len(x_train), 2)] + [(x_test[i], y_test[i]) for i in np.random.randint(0, len(x_test), 2)]):\n",
    "\n",
    "    #x speeds reconstruction\n",
    "    alphas, deltas = TWI_OMP(xs, Dx, tau=tau, r_window=20)\n",
    "\n",
    "    reconstructed_x_signal = np.zeros_like(xs)\n",
    "\n",
    "    for alpha, delta, atom in zip(alphas, deltas, Dx):\n",
    "        if alpha != 0:\n",
    "            reconstructed_x_signal += alpha * delta @ atom\n",
    "    \n",
    "    idx = np.argmax(alphas)\n",
    "    first_atom_x = alphas[idx] * deltas[idx] @ Dx[idx]\n",
    "    \n",
    "    # y reconstruction\n",
    "    alphas, deltas = TWI_OMP(ys, Dy, tau=tau, r_window=20)\n",
    "\n",
    "    reconstructed_y_signal = np.zeros_like(ys)\n",
    "\n",
    "    for alpha, delta, atom in zip(alphas, deltas, Dy):\n",
    "        if alpha != 0:\n",
    "            reconstructed_y_signal += alpha * delta @ atom\n",
    "            #plt.plot(alpha * delta @ atom)\n",
    "    \n",
    "    idx = np.argmax(alphas)\n",
    "    first_atom_y = alphas[idx] * deltas[idx] @ Dy[idx]\n",
    "\n",
    "    exsample = samples[i]\n",
    "\n",
    "    x_speed = reconstructed_x_signal\n",
    "    y_speed = reconstructed_y_signal\n",
    "    pen_tip_f = exsample[2]\n",
    "    \n",
    "\n",
    "    # Conversion to trajectory beggining at point (0,0)\n",
    "    x = [0]\n",
    "    y = [0]\n",
    "    f_x = [0]\n",
    "    f_y = [0]\n",
    "    x_t = [0]\n",
    "    y_t = [0]\n",
    "\n",
    "    for x_v, y_v in zip(x_speed, y_speed):\n",
    "        x.append(x[-1] + x_v/f_s)\n",
    "        y.append(y[-1] + y_v/f_s)\n",
    "    \n",
    "    for x_v, y_v in zip(exsample[0], exsample[1]):\n",
    "        x_t.append(x_t[-1] + x_v/f_s)\n",
    "        y_t.append(y_t[-1] + y_v/f_s)\n",
    "    \n",
    "    for x_v, y_v in zip(first_atom_x, first_atom_y):\n",
    "        f_x.append(f_x[-1] + x_v/f_s)\n",
    "        f_y.append(f_y[-1] + y_v/f_s)\n",
    "\n",
    "\n",
    "    plt.subplot(4, 3, 3*p + 1)\n",
    "    plt.plot(x, y, \"b\")\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    plt.ylabel(f\"Sample {p}\")\n",
    "    if p == 0:\n",
    "        plt.title(\"Reconstruction\")\n",
    "\n",
    "    plt.subplot(4, 3, 3*p + 2)\n",
    "    plt.plot(f_x, f_y, \"r\")\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    if p == 0:\n",
    "        plt.title(\"First atom\")\n",
    "\n",
    "    plt.subplot(4, 3, 3*p + 3)\n",
    "    plt.plot(x_t, y_t, \"g\")\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    if p == 0:\n",
    "        plt.title(\"Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, atom in enumerate(Dx):\n",
    "    os.makedirs(\"../trajectory_dataset/x_dictionnary\", exist_ok=True)\n",
    "    np.save(\"../trajectory_dataset/x_dictionnary/atom_\" + str(i) + \".npy\", atom)\n",
    "\n",
    "for i, atom in enumerate(Dy):\n",
    "    os.makedirs(\"../trajectory_dataset/y_dictionnary\", exist_ok=True)\n",
    "    np.save(\"../trajectory_dataset/y_dictionnary/atom_\" + str(i) + \".npy\", atom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
